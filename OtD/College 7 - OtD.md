# College 6 - OtD

The exceptions are interesting, not the mass.

# College 7 - OtD

## Humanities and interpretation

Fish is quite critical about DH research. He noticed that the new bisschops are much the same as the old presbiters. This is proper interpretative research. He looks for a pattern that supports his interpretation. 

Hermeneutic circle. Understand the whole from its part. 

In DH its the other way arround. You find a pattern and then you find an explaination for it. Also the tool dictates a lot of how the research is done. Some things are to general. Frequency is also not an argument to him. Relation formal feature to significance is not nessecairily true. 

The patern he spotted wasn't actually there. There is something interesting in the methods. To check each other. 

## Does the digital analysis exclude interpretation?

Does it sacrifice significance? Ambiguity, beauty? 
Does digital transfrom/affect interpretation?
Can digital methods perform interpretation?

Fish: Don't we have to actually read the books before saying what the patterns discovered in them mean? Nothing authorises this leap of fantasy?

Ramsay: text is the same as data. You always take a leap. 

Ramsay: pattern urge interpretations and interpretation bring forth patterns.
Should hacking be included in the loop of the hermeneutic circle? Reading, (talking), hacking, thinking, interpreting? 

(How far can you go away from the object and still claim to say something about it? ) (Is the Humanties breaching into the realm of social studies) 

## Pauze

## Big data

The end of theory. Does size really matter? Does interpretation change if you're looking at big sets. A difference in degree, becomes different kind. Micro vs Marcro. You spot different kinds of patterns. It becomes a different kind of thing. 

The buzz word big data is used for a lot things. Google Books hopes to achieve complete data. Correlation is all we need, causation in not that important, Anderson thinks. Google act on correlation, not causation. Do we need a theory on top of that? Who cares?

There are a lot of patterns, but only a few are meaningfull. Take the 1900, 1910, 1920, 1930, 1940, 1950. Problematic ngram project.

When is something big data? What is really the main issue behind big data? -> To much to analyse manually. Yet from many questions even megabytes are to much information. Depends on the question. Theory you also need, because everything is based on a data model. 

## Collaboration and the Humanities. 

80% Science and Enginering
51% Social sciences
< 10% Humanities

Why no collaboration.

2% - Normal Humanities.
48% - Digital Humanities.

Perhaps not recognised?
Quantative research lends itself better to this?
Myth of lone genius?
Humanities work with existing data sources(?).

Moretti: 
It doesnt matter who does the quantifying, as long a you agree on what to quantify.
-> But who does the interpretation get a different awnser. How to quantifiy something is also important. 

Computers are also different. Software is also interpreting, even for unix commands.

Why is collaboration more common in the Digital Humanties?
- Bigger projects
- More perspectives

Problems:
- Control and risking your own perspective being diminished
- Getting credit for collaborative work
- Communicating clearly. What and how to is difficult crossdiciplinairy.

## Building & Scholarship

Is building tools a form of scholarship... ? Are tool builders different from tool users?

Making vs Critiquing. Being able to understand validates your critique
